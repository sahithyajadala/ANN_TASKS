{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de224f18-428a-4f76-80f1-65dc1dbea523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Validation Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load training image data\n",
    "train_directory = '/home/sahitya-jadala/Downloads/1st_week_project/train'\n",
    "X_train = []\n",
    "y_train = []\n",
    "for filename in os.listdir(train_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions as per your images\n",
    "        image_path = os.path.join(train_directory, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "        # Resize image if needed\n",
    "        # image = cv2.resize(image, (desired_width, desired_height))\n",
    "        X_train.append(image.flatten())  # Flatten image array\n",
    "        label = 1 if \"class1\" in filename else -1  # Adjust label based on filename pattern\n",
    "        y_train.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Load validation image data\n",
    "valid_directory = '/home/sahitya-jadala/Downloads/1st_week_project/valid'\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "for filename in os.listdir(valid_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions as per your images\n",
    "        image_path = os.path.join(valid_directory, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "        # Resize image if needed\n",
    "        # image = cv2.resize(image, (desired_width, desired_height))\n",
    "        X_valid.append(image.flatten())  # Flatten image array\n",
    "        label = 1 if \"class1\" in filename else -1  # Adjust label based on filename pattern\n",
    "        y_valid.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "\n",
    "# Load test image data\n",
    "test_directory = '/home/sahitya-jadala/Downloads/1st_week_project/test'\n",
    "X_test = []\n",
    "y_test = []\n",
    "for filename in os.listdir(test_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions as per your images\n",
    "        image_path = os.path.join(test_directory, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "        # Resize image if needed\n",
    "        # image = cv2.resize(image, (desired_width, desired_height))\n",
    "        X_test.append(image.flatten())  # Flatten image array\n",
    "        label = 1 if \"class1\" in filename else -1  # Adjust label based on filename pattern\n",
    "        y_test.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Perceptron training without class or function\n",
    "eta = 0.1  # Learning rate\n",
    "n_iter = 100  # Number of epochs\n",
    "\n",
    "# Initialize weights and bias\n",
    "n_samples, n_features = X_train.shape\n",
    "weights = np.zeros(n_features)\n",
    "bias = 0\n",
    "\n",
    "# Training loop\n",
    "for _ in range(n_iter):\n",
    "    for i in range(n_samples):\n",
    "        linear_output = np.dot(X_train[i], weights) + bias\n",
    "        y_pred = np.where(linear_output >= 0, 1, -1)\n",
    "        update = eta * (y_train[i] - y_pred)\n",
    "        weights += update * X_train[i]\n",
    "        bias += update\n",
    "\n",
    "# Calculate training accuracy\n",
    "predictions_train = np.where(np.dot(X_train, weights) + bias >= 0, 1, -1)\n",
    "accuracy_train = np.mean(predictions_train == y_train) * 100\n",
    "print(f'Training Accuracy: {accuracy_train:.2f}%')\n",
    "\n",
    "# Predict on validation data and calculate accuracy\n",
    "predictions_valid = np.where(np.dot(X_valid, weights) + bias >= 0, 1, -1)\n",
    "accuracy_valid = np.mean(predictions_valid == y_valid) * 100\n",
    "print(f'Validation Accuracy: {accuracy_valid:.2f}%')\n",
    "\n",
    "# Predict on test data and calculate accuracy\n",
    "predictions_test = np.where(np.dot(X_test, weights) + bias >= 0, 1, -1)\n",
    "accuracy_test = np.mean(predictions_test == y_test) * 100\n",
    "print(f'Test Accuracy: {accuracy_test:.2f}%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93332030-a805-49f3-9e59-7b779b9ee9cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# smp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Flatten\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a679142-9d36-40bb-8842-41c326dcf826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m949.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting keras>=3.2.0\n",
      "  Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow) (24.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 KB\u001b[0m \u001b[31m358.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 KB\u001b[0m \u001b[31m931.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rich\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 KB\u001b[0m \u001b[31m652.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 KB\u001b[0m \u001b[31m985.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.17.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m575.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, werkzeug, markdown-it-py, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.4 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.7.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 werkzeug-3.0.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56528177-222c-44f3-862c-32157b4f511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# smp\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Load training data\n",
    "training_path = \"/home/sahitya-jadala/Downloads/1st_week_project/train/\"\n",
    "images = []\n",
    "labels = []\n",
    "for root, dirs, files in os.walk(training_path):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        label = os.path.basename(root)\n",
    "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            images.append(image.flatten())\n",
    "            labels.append(label)\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# Map labels to integers\n",
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train = np.array([label_to_int[label] for label in y_train])\n",
    "\n",
    "# Initialize perceptron\n",
    "input_size = X_train.shape[1]\n",
    "weights = np.zeros(input_size)\n",
    "bias = 0\n",
    "learning_rate = 0.1\n",
    "epochs = 1\n",
    "\n",
    "# Train perceptron\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        prediction = np.dot(X_train[i], weights) + bias\n",
    "        prediction = 1 if prediction >= 0 else 0\n",
    "        if prediction != y_train[i]:\n",
    "            update = learning_rate * (y_train[i] - prediction)\n",
    "            weights += update * X_train[i]\n",
    "            bias += update\n",
    "\n",
    "# Evaluate training accuracy\n",
    "correct = 0\n",
    "for i in range(len(X_train)):\n",
    "    prediction = np.dot(X_train[i], weights) + bias\n",
    "    prediction = 1 if prediction >= 0 else 0\n",
    "    if prediction == y_train[i]:\n",
    "        correct += 1\n",
    "train_acc = correct / len(X_train)\n",
    "print(f\"Training Accuracy: {train_acc:.2f}\")\n",
    "\n",
    "# Optionally, load validation data and evaluate accuracy\n",
    "validation_path = \"/home/sahitya-jadala/Downloads/1st_week_project/valid/\"\n",
    "images = []\n",
    "labels = []\n",
    "for root, dirs, files in os.walk(validation_path):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        label = os.path.basename(root)\n",
    "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            images.append(image.flatten())\n",
    "            labels.append(label)\n",
    "X_val = np.array(images)\n",
    "y_val = np.array(labels)\n",
    "\n",
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_val))}\n",
    "y_val = np.array([label_to_int[label] for label in y_val])\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X_val)):\n",
    "    prediction = np.dot(X_val[i], weights) + bias\n",
    "    prediction = 1 if prediction >= 0 else 0\n",
    "    if prediction == y_val[i]:\n",
    "        correct += 1\n",
    "val_acc = correct / len(X_val)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "# Optionally, load testing data and evaluate accuracy\n",
    "testing_path = \"/home/sahitya-jadala/Downloads/1st_week_project/test/\"\n",
    "images = []\n",
    "labels = []\n",
    "for root, dirs, files in os.walk(testing_path):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        label = os.path.basename(root)\n",
    "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (28, 28))\n",
    "            images.append(image.flatten())\n",
    "            labels.append(label)\n",
    "X_test = np.array(images)\n",
    "y_test = np.array(labels)\n",
    "\n",
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_test))}\n",
    "y_test = np.array([label_to_int[label] for label in y_test])\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    prediction = np.dot(X_test[i], weights) + bias\n",
    "    prediction = 1 if prediction >= 0 else 0\n",
    "    if prediction == y_test[i]:\n",
    "        correct += 1\n",
    "test_acc = correct / len(X_test)\n",
    "print(f\"Testing Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064a3b6b-4e7d-466e-b70f-94c180ac7841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahitya-jadala/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.4296 - val_accuracy: 0.9641 - val_loss: 0.1166\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1081 - val_accuracy: 0.9710 - val_loss: 0.0924\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0718 - val_accuracy: 0.9736 - val_loss: 0.0816\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0512 - val_accuracy: 0.9728 - val_loss: 0.0862\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9866 - loss: 0.0409 - val_accuracy: 0.9724 - val_loss: 0.0939\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0328 - val_accuracy: 0.9715 - val_loss: 0.1069\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0282 - val_accuracy: 0.9724 - val_loss: 0.1059\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0229 - val_accuracy: 0.9731 - val_loss: 0.0996\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0193 - val_accuracy: 0.9751 - val_loss: 0.0973\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0148 - val_accuracy: 0.9767 - val_loss: 0.0923\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0155 - val_accuracy: 0.9755 - val_loss: 0.1053\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0135 - val_accuracy: 0.9781 - val_loss: 0.0990\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9769 - val_loss: 0.1036\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0127 - val_accuracy: 0.9762 - val_loss: 0.1064\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.9790 - val_loss: 0.1029\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9762 - val_loss: 0.1263\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9765 - val_loss: 0.1194\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9775 - val_loss: 0.1208\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.9765 - val_loss: 0.1364\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9781 - val_loss: 0.1311\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9746 - loss: 0.1575\n",
      "Test accuracy: 0.9781000018119812\n"
     ]
    }
   ],
   "source": [
    "# mlp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Input values\n",
    "train_dir = '/home/sahitya-jadala/Downloads/1st_week_project/train'\n",
    "valid_dir = '/home/sahitya-jadala/Downloads/1st_week_project/valid'\n",
    "test_dir = '/home/sahitya-jadala/Downloads/1st_week_project/test'\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Reshape data to flatten the images (MLP input requirement)\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "\n",
    "# Convert labels to categorical one-hot encoded vectors\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1e3ac2-a659-48e1-a0bc-8027f203d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with L2 Regularization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahitya-jadala/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/home/sahitya-jadala/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-08-16 17:55:21.757305: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-08-16 17:55:21.909230: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-08-16 17:55:22.207747: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training with L1 Regularization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 17:55:23.831631: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training with Dropout:\n",
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training with Batch Normalization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 17:55:27.508215: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.0313\n",
      "Validation accuracy: 0.0208\n",
      "Test accuracy: 0.0104\n",
      "\n",
      "Final Training Accuracies:\n",
      "L2 Regularization: 1.0000\n",
      "L1 Regularization: 1.0000\n",
      "Dropout: 1.0000\n",
      "Batch Normalization: 0.0313\n",
      "\n",
      "Final Validation Accuracies:\n",
      "L2 Regularization: 1.0000\n",
      "L1 Regularization: 1.0000\n",
      "Dropout: 1.0000\n",
      "Batch Normalization: 0.0208\n",
      "\n",
      "Final Testing Accuracies:\n",
      "L2 Regularization: 1.0000\n",
      "L1 Regularization: 1.0000\n",
      "Dropout: 1.0000\n",
      "Batch Normalization: 0.0104\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(np.array(img))\n",
    "    return np.array(images)\n",
    "\n",
    "# Define paths\n",
    "train_path = '/home/sahitya-jadala/Downloads/1st_week_project/train/'\n",
    "valid_path = '/home/sahitya-jadala/Downloads/1st_week_project/valid/'\n",
    "test_path = '/home/sahitya-jadala/Downloads/1st_week_project/test/'\n",
    "\n",
    "# Load data\n",
    "X_train = load_images_from_folder(train_path)\n",
    "X_valid = load_images_from_folder(valid_path)\n",
    "X_test = load_images_from_folder(test_path)\n",
    "\n",
    "\n",
    "y_train = np.array([0] * len(X_train))  \n",
    "y_valid = np.array([0] * len(X_valid)) \n",
    "y_test = np.array([0] * len(X_test))    \n",
    "\n",
    "# Define image dimensions\n",
    "image_width = X_train.shape[1]\n",
    "image_height = X_train.shape[2]\n",
    "\n",
    "# If images are grayscale (single channel), adjust accordingly\n",
    "if len(X_train.shape) == 3:\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_valid = np.expand_dims(X_valid, axis=-1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "    num_channels = 1\n",
    "else:\n",
    "    num_channels = X_train.shape[3]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Regularization techniques to try\n",
    "regularization_techniques = [\n",
    "    {'name': 'L2 Regularization', 'reg': regularizers.l2(0.001)},\n",
    "    {'name': 'L1 Regularization', 'reg': regularizers.l1(0.001)},\n",
    "    {'name': 'Dropout', 'reg': None},\n",
    "    {'name': 'Batch Normalization', 'reg': None}\n",
    "]\n",
    "\n",
    "# Initialize lists to store accuracies\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through regularization techniques\n",
    "for reg in regularization_techniques:\n",
    "    print(f\"\\nTraining with {reg['name']}:\")\n",
    "\n",
    "    # Example model with regularization technique\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(image_width, image_height, num_channels)),\n",
    "        Dense(128, activation='relu', kernel_regularizer=reg['reg']),\n",
    "    ])\n",
    "\n",
    "    # Conditionally add Dropout or BatchNormalization layer\n",
    "    if reg['name'] == 'Dropout':\n",
    "        model.add(Dropout(0.5))\n",
    "    elif reg['name'] == 'Batch Normalization':\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    # Add more layers\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=reg['reg']))\n",
    "\n",
    "    # Conditionally add Dropout or BatchNormalization layer\n",
    "    if reg['name'] == 'Dropout':\n",
    "        model.add(Dropout(0.3))\n",
    "    elif reg['name'] == 'Batch Normalization':\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train-validation split\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model using Data Augmentation\n",
    "    batch_size = 32\n",
    "    steps_per_epoch = len(X_train_split) // batch_size\n",
    "    history = model.fit(datagen.flow(X_train_split, y_train_split, batch_size=batch_size),\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0)  # Set verbose to 0 to suppress training output\n",
    "\n",
    "    # Evaluate on training set\n",
    "    train_loss, train_acc = model.evaluate(X_train_split, y_train_split, verbose=0)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f'Training accuracy: {train_acc:.4f}')\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    valid_accuracies.append(val_acc)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Print final accuracies for each regularization technique\n",
    "print(\"\\nFinal Training Accuracies:\")\n",
    "for i, reg in enumerate(regularization_techniques):\n",
    "    print(f\"{reg['name']}: {train_accuracies[i]:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Validation Accuracies:\")\n",
    "for i, reg in enumerate(regularization_techniques):\n",
    "    print(f\"{reg['name']}: {valid_accuracies[i]:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Testing Accuracies:\")\n",
    "for i, reg in enumerate(regularization_techniques):\n",
    "    print(f\"{reg['name']}: {test_accuracies[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7107b536-831d-4419-87db-783c929647d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Adam optimizer:\n",
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training with RMSprop optimizer:\n",
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training with SGD optimizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 17:56:55.521219: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0000\n",
      "Validation accuracy: 1.0000\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Final Training Accuracies:\n",
      "Adam: 1.0000\n",
      "RMSprop: 1.0000\n",
      "SGD: 1.0000\n",
      "\n",
      "Final Validation Accuracies:\n",
      "Adam: 1.0000\n",
      "RMSprop: 1.0000\n",
      "SGD: 1.0000\n",
      "\n",
      "Final Testing Accuracies:\n",
      "Adam: 1.0000\n",
      "RMSprop: 1.0000\n",
      "SGD: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# optimizers\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_path = '/home/sahitya-jadala/Downloads/1st_week_project/train/'\n",
    "valid_path = '/home/sahitya-jadala/Downloads/1st_week_project/valid/'\n",
    "test_path = '/home/sahitya-jadala/Downloads/1st_week_project/test/'\n",
    "\n",
    "# Optimizers to try\n",
    "optimizers = [\n",
    "    {'name': 'Adam', 'optimizer': Adam()},\n",
    "    {'name': 'RMSprop', 'optimizer': RMSprop()},\n",
    "    {'name': 'SGD', 'optimizer': SGD()}\n",
    "]\n",
    "\n",
    "# Initialize lists to store accuracies\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through optimizers\n",
    "for opt in optimizers:\n",
    "    print(f\"\\nTraining with {opt['name']} optimizer:\")\n",
    "\n",
    "    # Load data for this optimizer\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for filename in os.listdir(train_path):\n",
    "        img = Image.open(os.path.join(train_path, filename))\n",
    "        if img is not None:\n",
    "            X_train.append(np.array(img))\n",
    "            y_train.append(0)  # Replace with actual labels loading\n",
    "\n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    for filename in os.listdir(valid_path):\n",
    "        img = Image.open(os.path.join(valid_path, filename))\n",
    "        if img is not None:\n",
    "            X_valid.append(np.array(img))\n",
    "            y_valid.append(0)  # Replace with actual labels loading\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for filename in os.listdir(test_path):\n",
    "        img = Image.open(os.path.join(test_path, filename))\n",
    "        if img is not None:\n",
    "            X_test.append(np.array(img))\n",
    "            y_test.append(0)  # Replace with actual labels loading\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_valid = np.array(X_valid)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Define image dimensions\n",
    "    image_width = X_train.shape[1]\n",
    "    image_height = X_train.shape[2]\n",
    "\n",
    "    # If images are grayscale (single channel), adjust accordingly\n",
    "    if len(X_train.shape) == 3:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_valid = np.expand_dims(X_valid, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "        num_channels = 1\n",
    "    else:\n",
    "        num_channels = X_train.shape[3]\n",
    "\n",
    "    # Data Augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Example model without regularization\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(image_width, image_height, num_channels)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model with optimizer\n",
    "    model.compile(optimizer=opt['optimizer'],\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train-validation split\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model using Data Augmentation\n",
    "    batch_size = 32\n",
    "    steps_per_epoch = len(X_train_split) // batch_size\n",
    "    history = model.fit(datagen.flow(X_train_split, y_train_split, batch_size=batch_size),\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0)  # Set verbose to 0 to suppress training output\n",
    "\n",
    "    # Evaluate on training set\n",
    "    train_loss, train_acc = model.evaluate(X_train_split, y_train_split, verbose=0)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f'Training accuracy: {train_acc:.4f}')\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    valid_accuracies.append(val_acc)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Print final accuracies for each optimizer\n",
    "print(\"\\nFinal Training Accuracies:\")\n",
    "for i in range(len(optimizers)):\n",
    "    print(f\"{optimizers[i]['name']}: {train_accuracies[i]:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Validation Accuracies:\")\n",
    "for i in range(len(optimizers)):\n",
    "    print(f\"{optimizers[i]['name']}: {valid_accuracies[i]:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Testing Accuracies:\")\n",
    "for i in range(len(optimizers)):\n",
    "    print(f\"{optimizers[i]['name']}: {test_accuracies[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4e4b1-5b66-431e-bab1-7ab2361f3f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
